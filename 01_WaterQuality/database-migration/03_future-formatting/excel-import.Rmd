# Import data from Excel Field Data Sheets

# 2/11/25

# Part 1: Import from Sheets

```{r}
library(readxl)
library(stringr)
library(tidyverse)
library(lubridate)
source('00_GlobalFunctions/functions.R')

fp <- abs_path_emp('Water Quality/00 - Monthly Run Docs/Raw Field Data/Water Quality 2025/01 - January/EMP Field Data Sheet_SB_Jan25.xlsx')

df <- read_excel(fp, col_names = FALSE)
```

```{r}
# extract top box info
df_head <- df %>%
  select('...7', '...9', '...18', '...24') %>%
  rename(param1 = '...7', value1 = '...9', param2 = '...18', value2 = '...24') %>%
  pivot_longer(cols = c(param1, param2), values_to = 'param', names_to = 'param_col') %>%
  pivot_longer(cols = c(value1, value2), values_to = 'value', names_to = 'value_col') %>%
  mutate(
    param_suffix = str_extract(param_col, '\\d+$'),
    value_suffix = str_extract(value_col, '\\d+$')
  ) %>%
  filter(param_suffix == value_suffix) %>%
  select(param, value) %>%
  filter(!is.na(param) & !is.na(value)) %>%
  mutate(value = case_when(
    param == 'Date:' ~ format(as.Date(as.numeric(value), origin = '1899-12-30'), '%m/%d/%Y'),
    TRUE ~ value
  ),
  batch_id = 0)
```

```{r}
# extract blank info
df_blank <- df %>%
  select(...38, ...39, ...40, ...41, ...42, ...43, ...44) %>%
  filter(!is.na(...38) | ...38 == 'Equipment Blank') %>%
  pivot_longer(cols = c(...39, ...40, ...41, ...42, ...43, ...44), values_to = 'value', names_to = 'value_col') %>%
  filter(!is.na(value) | ...38 == 'Equipment Blank') %>%
  mutate(
    param = case_when(
      ...38 == 'Equipment Blank' ~ 'Station',
      TRUE ~ ...38
    ),
    value = case_when(
      ...38 == 'Equipment Blank' ~ 'Equipment Blank',
      TRUE ~ value
    ),
    `QC: Type` = 'Blank',
    batch_id = 999,
  ) %>%
  filter(!(duplicated(param))) %>%
  select(param, value, batch_id, `QC: Type`)

df_blank <- df_blank %>%
  mutate(
    param = case_when(
      param == 'Churn Bucket #:' ~ 'Churn Bucket #',
      param == 'Time:' ~ 'Time',
      param == 'Lab ID:' ~ 'Lab ID',
      TRUE ~ param
    )
  )
```

```{r}
# define each chunk of station info as a 'batch'
df_batch <- df %>%
  mutate(across(everything(), ~ str_replace_all(., '[\r\n]', ' '))) %>%
  mutate(
    batch_start = ifelse(!is.na(...1) & str_detect(...1, 'Station:'), TRUE, FALSE),
    batch_end = ifelse(!is.na(...1) & str_detect(...1, 'Notes:'), TRUE, FALSE),
    batch_id = cumsum(batch_start)
  ) %>%
  fill(batch_id, .direction = 'down') %>%
  group_by(batch_id) %>%
  mutate(
    in_batch = cumsum(batch_start) > cumsum(batch_end) | batch_end
  ) %>%
  ungroup() %>%
  filter(in_batch | batch_start | batch_end) %>%
  select(-batch_start, -batch_end, -in_batch) %>%
  select(where(~ any(!is.na(.)))) %>%
  filter(rowSums(!is.na(select(., -batch_id))) > 0)

rm_batches <- df_batch %>%
  filter(str_detect(...1, 'Station:') & str_detect(...1, 'Check')) %>%
  pull(batch_id) %>%
  unique()

df_batch <- df_batch %>%
  filter(!batch_id %in% rm_batches)
```

```{r}
# format batches

# 1. define batches
df_batch <- df_batch %>%
  group_by(batch_id) %>%
  mutate(
    is_header1 = str_detect(...1, 'Station:'),
    is_horz = str_detect(...1, 'Horizontal'),
    is_pretow_surf = str_detect(...1, 'Pre-Tow Surf'),
    is_pretow_bot = str_detect(...1, 'Pre-Tow Bot'),
    is_header2 = str_detect(...1, 'Lab ID'),
    is_discval = case_when(
      lag(is_header2, default = FALSE) & !is.na(...1) ~ TRUE,
      TRUE ~ FALSE),
    is_notes = str_detect(...1, 'Notes:'),
    is_lat = str_detect(...39, 'Lat:'),
    is_long = str_detect(...39, 'Long:')
  ) %>%
  ungroup()

# 2. pivot to long
df_long <- df_batch %>%
  pivot_longer(cols = -c(batch_id, is_header1, is_horz, is_pretow_surf,
                         is_pretow_bot, is_header2, is_discval, is_notes,
                         is_lat, is_long),
               names_to = 'col', values_to = 'cell_value') %>%
  filter(!is.na(cell_value))  

# 3. extract main information (sonde and observations)
df_values <- df_long %>%
    filter(is_horz | is_pretow_surf | is_pretow_bot | is_discval) %>%
    mutate(
        SondeType = case_when(
            is_horz ~ 'horizontal',
            is_pretow_surf ~ 'vertical',
            is_pretow_bot ~ 'vertical',
            TRUE ~ NA_character_
        ),
        SurfBot = case_when(
            is_pretow_surf ~ 'surface',
            is_pretow_bot ~ 'bottom',
            TRUE ~ NA_character_
        )
    ) %>%
    left_join(df_long %>% filter(is_header2) %>% select(batch_id, col, header_param = cell_value),
              by = c('batch_id', 'col')) %>%
    left_join(df_long %>% filter(is_header1) %>% select(batch_id, col, header1_param = cell_value),
              by = c('batch_id', 'col')) %>%
    mutate(
        param = case_when(
            is_discval ~ header_param,
            !is.na(SondeType) | !is.na(SurfBot) ~ header1_param,
            TRUE ~ col
        )
    ) %>%
    filter(!(cell_value %in% c('Horizontal', 'Pre-Tow Surf.', 'Pre-Tow Bot.'))) %>%
    select(batch_id, param, value = cell_value, SondeType, SurfBot)

# 4. extract station/time
df_station <- df_long %>%
    filter(is_header1) %>%
    mutate(
        station_value = str_extract(cell_value, '(?<=Station: )[^ ]+'),
        time_value = str_extract(cell_value, '(?<=Time: )\\S+') 
    ) %>%
    select(batch_id, station_value, time_value) %>%
    pivot_longer(cols = c(station_value, time_value), names_to = 'param', values_to = 'value') %>%
    mutate(param = case_when(
        param == 'station_value' ~ 'Station',
        param == 'time_value' ~ 'Time',
        TRUE ~ param
    )) %>%
    filter(!is.na(value))

# 5. extract notes
df_notes <- df_long %>%
    filter(is_notes) %>%
    mutate(param = 'Notes', value = cell_value) %>%
    filter(value != 'Notes:') %>%
    select(batch_id, param, value)

# 6. extract lat/lon
df_latlong <- df_long %>%
  filter(is_lat | is_long) %>%
  mutate(
    param = case_when(is_lat ~ 'latitude', is_long ~ 'longitude'),
    value = str_extract(cell_value, '-?\\d+\\.\\d+')
  ) %>%
  select(batch_id, param, value)

# 7. extract duplicate info
df_dup <- df_long %>%
  filter(is_header1) %>%
  mutate(
    duplicate_value = str_extract(cell_value, '(?<=Duplicate\\? )\\S+'),
    churn_bucket_value = str_extract(cell_value, '(?<=Churn Bucket #: )\\S+'),
    lab_id_value = str_extract(cell_value, '(?<=Lab ID )\\S+')
  ) %>%
  filter(duplicate_value == 'True') %>%
  select(batch_id, churn_bucket_value, lab_id_value) %>%
  pivot_longer(
    cols = c(churn_bucket_value, lab_id_value),
    names_to = 'param',
    values_to = 'value'
  ) %>%
  mutate(
    param = case_when(
      param == 'churn_bucket_value' ~ 'Churn Bucket #',
      param == 'lab_id_value' ~ 'Lab ID',
      TRUE ~ param
    ),
    `QC: Type` = 'Replicate'
  ) %>%
  filter(!is.na(value))
```

```{r}
# combine all batches
df_final <- bind_rows(df_head, df_station, df_values, df_notes, df_latlong, df_dup, df_blank) %>%
  arrange(batch_id) %>%
  relocate(batch_id)

rm(df, df_batch, df_blank, df_dup, df_head, df_latlong, df_long, df_notes, df_station, df_values)
```

# Part 2: Format

```{r}
# Remove extra params
df_final <- df_final %>%
  filter(!(param %in% c('Vessel:','Crew:','Run Name:','Operator:','Run Type:','Sonde ID (H):','ChloroVol(ml)'))) %>%
  filter(SondeType == 'vertical' | is.na(SondeType)) %>%
  mutate(param = str_squish(param))

# Extract relevant values
date_value <- df_final %>%
  filter(batch_id == 0, param == 'Date:') %>%
  pull(value) %>%
  mdy()

sonde_id <- df_final %>%
  filter(batch_id == 0, param == 'Sonde ID (V):') %>%
  pull(value)

station_vals <- df_final %>%
  filter(param == 'Station') %>%
  select(batch_id, `Location ID` = value)

lab_ids <- df_final %>%
  filter(param == 'Lab ID') %>%
  select(batch_id, `QC: Type`, `Activity Name` = value)

# Assign values as columns
# Add DateTime column
df_final <- df_final %>%
  mutate(`Observed DateTime` = case_when(
    param == 'Time' ~ date_value + hms(paste0(value, ':00')),
    TRUE ~ NA_POSIXct_
  )) %>%
  group_by(batch_id) %>%
  fill(`Observed DateTime`, .direction = 'downup') %>%
  ungroup()

# Assign sonde ID
df_final <- df_final %>%
  mutate(`Field: Device ID` = case_when(
    SondeType == 'vertical' ~ sonde_id,
    TRUE ~ NA_character_
  ))

# Merge the Station values
df_final <- df_final %>%
  left_join(station_vals, by = 'batch_id')

# Merge the Lab IDs
df_final <- df_final %>%
  left_join(lab_ids, by = c('batch_id', 'QC: Type'))

# Populate water depth for bottom readings
df_final <- df_final %>%
  mutate(
    water_depth = case_when(
      param == 'Water Depth (ft)' ~ as.numeric(value),
      TRUE ~ NA_real_
    )
  ) %>%
  group_by(batch_id) %>%
  fill(water_depth, .direction = 'downup') %>%
  ungroup() %>%
  mutate(
    Depth = case_when(
      SurfBot == 'bottom' ~ as.numeric(water_depth) - 3,
      SurfBot == 'surface' ~ 3,
      param == 'MC Score (1-5)' ~ 0,
      TRUE ~ NA_real_
    )
  ) %>%
  select(-water_depth)

# Assign filter jugs
df_final <- df_final %>%
  mutate(
    # extract filter jug IDs based on different QC types
    standard_jug = case_when(
      param == 'Notes' & str_detect(value, 'filter jug: [^;]+') ~ str_extract(value, '(?<=filter jug: )[^;]+'),
      TRUE ~ NA_character_
    ),
    duplicate_jug = case_when(
      param == 'Notes' & str_detect(value, 'duplicate filter jug: [^;]+') ~ str_extract(value, '(?<=duplicate filter jug: )[^;]+'),
      TRUE ~ NA_character_
    ),
    blank_jug = case_when(
      param == 'Notes' & str_detect(value, 'blank filter jug: [^;]+') ~ str_extract(value, '(?<=blank filter jug: )[^;]+'),
      TRUE ~ NA_character_
    )
  ) %>%
  # fill extracted values
  group_by(batch_id) %>%
  fill(standard_jug, .direction = 'downup') %>%
  ungroup() %>%
  fill(duplicate_jug, blank_jug, .direction = 'downup') %>%
  ungroup() %>%
  # populate Filter Container ID
  mutate(
    `EA_Filter Container ID` = case_when(
      `QC: Type` == 'Replicate' ~ duplicate_jug,
      `QC: Type` == 'Blank' ~ blank_jug,
      is.na(`QC: Type`) ~ standard_jug
    ),
    # remove filter substrings
    value = case_when(
      param == 'Notes' ~ str_remove_all(value, '\\b[^;]*filter jug: [^;]+;?\\s*'),
      TRUE ~ value
    )
  ) %>%
  select(-standard_jug, -duplicate_jug, -blank_jug)

# Add Field Notes col
notes_vals <- df_final %>%
  filter(param == 'Notes') %>%
  select(batch_id, `Field: Comment` = value)

# Merge the Station values
df_final <- df_final %>%
  left_join(notes_vals, by = 'batch_id')

# Remove extra rows
df_final <- df_final %>%
  filter(!(param %in% c('Date:','Sonde ID (V):','Station','Time','Lab ID','Notes')))

df_final <- df_final %>%
  mutate(
    `Location ID` = case_when(
      grepl('EZ',`Location ID`) ~ str_replace(`Location ID`, 'EZ', 'LSZ'),
      TRUE ~ `Location ID`),
    `Field: Comment` = str_remove(`Field: Comment`, ';\\s*$')
  ) %>%
  filter(!(param %in% c('latitude', 'longitude') & !grepl('LSZ', `Location ID`))) %>%
  relocate(SurfBot, .after = param)
```

```{r}
# Move filter ID to observed property
churn_rows <- df_final %>%
  group_by(batch_id, `QC: Type`) %>%
  filter(param == 'Churn Bucket #') %>%
  select(-value) %>%
  ungroup()

filter_vals <- df_final %>%
  filter(!is.na(`EA_Filter Container ID`)) %>%
  distinct(batch_id, `QC: Type`, `EA_Filter Container ID`)

new_rows <- churn_rows %>%
  left_join(filter_vals, by = c('batch_id', 'QC: Type', 'EA_Filter Container ID')) %>%
  mutate(param = 'Filter Container ID', value = `EA_Filter Container ID`) %>%
  select(-`EA_Filter Container ID`)

df_final <- bind_rows(df_final, new_rows) %>%
  select(-`EA_Filter Container ID`) %>%
  arrange(batch_id, `QC: Type`, SurfBot)

# Remap Sky and Rain
df_final <- df_final %>%
  mutate(value = case_when(
    param == 'Sky' & value == 'S' ~ 'Sunny',
    param == 'Sky' & value == 'PC' ~ 'Partly Cloudy',
    param == 'Sky' & value == 'C' ~ 'Cloudy',
    param == 'Sky' & value == 'O' ~ 'Overcast',
    param == 'Sky' & value == 'F' ~ 'Foggy',
    param == 'Rain' & value == 'N' ~ 'None',
    param == 'Rain' & value == 'L' ~ 'Light',
    param == 'Rain' & value == 'M' ~ 'Medium',
    param == 'Rain' & value == 'H' ~ 'Heavy',
    TRUE ~ value
  ))

# final rounding
df_final <- df_final %>%
  mutate(value = case_when(
    param == 'Turbidity (FNU)' ~ as.character(round(as.numeric(value), 1)),
    param == 'DO (mg/L)' ~ as.character(round(as.numeric(value), 2)),
    TRUE ~ value)
  )

# add parent sample ID
df_final <- df_final %>%
  group_by(`Location ID`) %>% 
  mutate(
    `EA_Parent Sample ID` = case_when(
      `QC: Type` == 'Replicate' ~ first(`Activity Name`[is.na(`QC: Type`)]),
      TRUE ~ NA_character_),
    `QC: Source Sample ID` = `EA_Parent Sample ID`
    ) %>%
  ungroup()

# remove extras
df_final <- df_final %>%
  select(-c(batch_id,SondeType)) %>%
  rename(`Result Value` = value)

df_final <- df_final %>%
  filter(!(is.na(`Result Value`)))

rm(churn_rows, filter_vals, lab_ids, new_rows, station_vals)
```

```{r}
# df_test3 <- df_final

# write_csv(df_final, 'C:/Users/sperry/Desktop/df_final.csv')
# write_csv(df_meta, 'C:/Users/sperry/Desktop/df_meta.csv')
```

```{r}
# fix depth

# re-format water and sampling depth
df_final <- df_final %>% 
  rename(`EA_Sampling Depth` = Depth) %>%
  mutate(Depth = case_when(
    grepl('Water Depth', param, ignore.case = TRUE) ~ `Result Value`,
    TRUE ~ NA)) %>%
  group_by(`Location ID`, `Observed DateTime`) %>%
  fill(Depth, .direction = 'downup') %>%
  ungroup()
```


```{r}
# combine with metadata
fp_meta <- abs_path_emp('Water Quality/AQUARIUS Samples Database/Database Migration/Lists to Import/Final Imports/Import_FDS Metadata.csv')
df_meta <- read_csv(fp_meta, show_col_types = FALSE)

df_final <- full_join(df_meta, df_final, by = c('param', 'SurfBot')) %>%
  select(-c(param, SurfBot))

# fix analyzed datetime
df_final <- df_final %>%
  mutate(`Analyzed DateTime` = format(mdy_hm(`Analyzed DateTime`), '%Y-%m-%d %H:%M:%S'))

# add PST to all DateTimes
df_final <- df_final %>%
  mutate(across(contains('DateTime'), ~ ifelse(is.na(.x), NA, paste0(.x, ' [PST]'))))

# have depth unit be ft except for blank
df_final <- df_final %>%
  mutate(`Depth Unit` = case_when(
    `Location ID` == 'Equipment Blank' ~ NA,
    TRUE ~ 'ft'
  ))

col_order <- c(
  'Observation ID', 'Location ID', 'Observed Property ID', 'Observed DateTime', 'Analyzed DateTime', 
  'Depth', 'Depth Unit', 'Data Classification', 'Result Value', 'Result Unit', 'Result Status', 
  'Result Grade', 'Medium', 'Activity Name', 'Activity ID', 'Collection Method', 'Field: Device ID', 
  'Field: Device Type', 'Field: Comment', 'Lab: Specimen Name', 'Lab: Analysis Method', 
  'Lab: Detection Condition', 'Lab: Limit Type', 'Lab: MDL', 'Lab: MRL', 'Lab: Quality Flag', 
  'Lab: Received DateTime', 'Lab: Prepared DateTime', 'Lab: Sample Fraction', 'Lab: From Laboratory', 
  'Lab: Sample ID', 'Lab: Dilution Factor', 'Lab: Comment', 'QC: Type', 'QC: Source Sample ID', 
  'EA_Modified Method', 'EA_Profile Type', 'EA_Project Type', 'EA_Reports To', 
  'EA_Parent Sample ID', 'EA_Data Review Flag', 'EA_Sampling Depth'
)

# Rearrange the dataframe `df` to match the specified column order
df_final <- df_final %>% select(all_of(col_order)) %>%
    arrange(`Activity Name`, `Data Classification`)

# define the filepath for saving
fp_export <- abs_path_emp('Water Quality/AQUARIUS Samples Database/Database Migration/Formatted FDS Data')

df_list <- split(df_final,
                 list(year(df_final$`Observed DateTime`),
                      ifelse(month(df_final$`Observed DateTime`) <= 6, 'JanJun', 'JulDec'),
                      ifelse(df_final$`Data Classification` == 'FIELD_RESULT', 'Field', 'Lab'),
                      month(df_final$`Observed DateTime`, label = TRUE, abbr = TRUE)),
                 drop = TRUE)

# # split the dataframe
invisible(lapply(names(df_list), function(name) {
  name_parts <- unlist(strsplit(name, '\\.'))
  year <- name_parts[1]
  half_year <- name_parts[2]
  data_class <- name_parts[3]
  month <- name_parts[4]

  fp_exp <- paste0(fp_export, '/', year, '-', half_year, '-',data_class,'_EMP-DWQ','_',month,'.csv')

  # write to .csv
  write_csv(df_list[[name]], file = fp_exp, na = '')
}))
```
